{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, header=None, index_col=None, delimiter=',')\n",
    "test_df = pd.read_csv(test_path, header=None, index_col=None, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 获取原始各类别数量\n",
    "l0_train, l1_train, l2_train = [train_df[train_df[0] == i] for i in [0, 1, 2]]\n",
    "l0_size, l1_size, l2_size = [df.shape[0] for df in [l0_train, l1_train, l2_train]]\n",
    "\n",
    "# 计算复制比例\n",
    "l0_l1_ratio = l0_size // l1_size\n",
    "l0_l2_ratio = l0_size // l2_size\n",
    "\n",
    "# 扩充样本数量\n",
    "l1_train_repeated = l1_train.sample(l0_size, replace=True)\n",
    "l2_train_repeated = l2_train.sample(l0_size, replace=True)\n",
    "\n",
    "# 合并扩充后的数据集\n",
    "train_df_balanced = pd.concat([l0_train, l1_train_repeated, l2_train_repeated])\n",
    "\n",
    "# 随机打乱数据\n",
    "train_df_balanced = shuffle(train_df_balanced)\n",
    "\n",
    "# 更新类别数量和比例\n",
    "l0_size, l1_size, l2_size = [train_df_balanced[train_df_balanced[0] == i].shape[0] for i in [0, 1, 2]]\n",
    "l0_l1_ratio, l0_l2_ratio = [(l0_size // l1_size), (l0_size // l2_size)]\n",
    "\n",
    "print(\"After\")\n",
    "print(f\"l0_size: {l0_size}, l1_size: {l1_size}, l2_size: {l2_size}\")\n",
    "print(f\"l0_l1_ratio: {l0_l1_ratio}, l0_l2_ratio: {l0_l2_ratio}\")\n",
    "\n",
    "# 重置索引\n",
    "train_df_balanced.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"train_df size: \", train_df_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill params dict before call train_cnn\n",
    "params = {\"input_w\": 15, \"input_h\": 15,\n",
    "          \"num_classes\": 3, \"batch_size\": 512, \"epochs\": 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(training_df, test_df, params):\n",
    "    \"\"\"Trains and evaluates CNN on the given train and test data, respectively.\"\"\"\n",
    "\n",
    "    print(\"Training is starting ...\")\n",
    "    train_images = training_df.iloc[:, 2:].to_numpy()\n",
    "    train_labels = training_df.iloc[:, 0]\n",
    "    train_prices = training_df.iloc[:, 1]\n",
    "\n",
    "    test_images = test_df.iloc[:, 2:].to_numpy()\n",
    "    test_labels = test_df.iloc[:, 0]\n",
    "    test_prices = test_df.iloc[:, 1]\n",
    "\n",
    "    test_labels = keras.utils.np_utils.to_categorical(\n",
    "        test_labels, params[\"num_classes\"])\n",
    "    train_labels = keras.utils.np_utils.to_categorical(\n",
    "        train_labels, params[\"num_classes\"])\n",
    "\n",
    "    train_images = train_images.reshape(\n",
    "        train_images.shape[0], params[\"input_w\"], params[\"input_h\"], 1)\n",
    "    test_images = test_images.reshape(\n",
    "        test_images.shape[0], params[\"input_w\"], params[\"input_h\"], 1)\n",
    "\n",
    "    # CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(\n",
    "        params[\"input_w\"], params[\"input_h\"], 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(params[\"num_classes\"], activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=Adadelta(),\n",
    "                  metrics=['accuracy', 'mae', 'mse'])\n",
    "\n",
    "    # metrics.accuracy_score, metrics.recall_score, metrics.average_precision_score, metrics.confusion_matrix\n",
    "    train_data_size = train_images.shape[0]\n",
    "    test_data_size = test_images.shape[0]\n",
    "\n",
    "    print(\"model will be trained with {} and be tested with {} sample\".format(\n",
    "        train_data_size, test_data_size))\n",
    "    # fit the model to the training data\n",
    "    print(\"Fitting model to the training data...\")\n",
    "    print(\"\")\n",
    "    model.fit(train_images, train_labels,\n",
    "              batch_size=params[\"batch_size\"], epochs=params[\"epochs\"], verbose=1, validation_data=None)\n",
    "\n",
    "    predictions = model.predict(\n",
    "        test_images, batch_size=params[\"batch_size\"], verbose=1)\n",
    "    print(model.evaluate(test_images, test_labels,\n",
    "          batch_size=params[\"batch_size\"], verbose=1))\n",
    "\n",
    "    print(\"Train conf matrix: \\n\", confusion_matrix(np.array(reverse_one_hot(train_labels)),\n",
    "                                                  np.array(reverse_one_hot(model.predict(train_images, batch_size=params[\"batch_size\"], verbose=1)))))\n",
    "\n",
    "    print(\"Test conf matrix: \\n\",  confusion_matrix(np.array(reverse_one_hot(test_labels)),\n",
    "                                                  np.array(reverse_one_hot(predictions))))\n",
    "\n",
    "    return predictions, test_labels, test_prices\n",
    "\n",
    "def reverse_one_hot(predictions):\n",
    "    reversed_x = []\n",
    "    for x in predictions:\n",
    "        reversed_x.append(np.argmax(np.array(x)))\n",
    "    return reversed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, test_labels, test_prices = train_cnn(train_df_balanced, test_df, params)\n",
    "result_df = pd.DataFrame({\"prediction\": np.argmax(predictions, axis=1),\n",
    "                          \"test_label\": np.argmax(test_labels, axis=1),\n",
    "                         \"test_price\": test_prices})\n",
    "result_df.to_csv(\"cnn_result.csv\", sep=',', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CNN import *\n",
    "cnn = CNN()\n",
    "train_path = '.\\\\dataset\\\\set-0\\\\output_phase2_train.csv'\n",
    "test_path = '.\\\\dataset\\\\set-0\\\\output_phase2_test.csv'\n",
    "train_df, test_df = cnn.preProcess(train_path=train_path, test_path=test_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, test_labels, test_prices = cnn.train(training_df=train_df, test_df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
